"""
ç®—æ³•æ¸¸ä¹åœº - äº¤äº’å¼ç®—æ³•å‚æ•°è°ƒæ•´å’Œå¯è§†åŒ–
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
import time
import random
from dataclasses import dataclass
from abc import ABC, abstractmethod

# ç®—æ³•åŸºç±»
class Algorithm(ABC):
    """ç®—æ³•åŸºç±»"""
    
    def __init__(self, name: str):
        self.name = name
        self.parameters = {}
        self.results = {}
        self.history = []
    
    @abstractmethod
    def run(self, data: Any, **kwargs) -> Any:
        """è¿è¡Œç®—æ³•"""
        pass
    
    @abstractmethod
    def get_parameters(self) -> Dict[str, Any]:
        """è·å–å¯è°ƒæ•´çš„å‚æ•°"""
        pass
    
    @abstractmethod
    def visualize(self, data: Any, results: Any) -> None:
        """å¯è§†åŒ–ç»“æœ"""
        pass

# æœç´¢ç®—æ³•æ¸¸ä¹åœº
class SearchAlgorithmPlayground:
    """æœç´¢ç®—æ³•æ¸¸ä¹åœº"""
    
    def __init__(self):
        self.algorithms = {
            'BFS': BreadthFirstSearch(),
            'DFS': DepthFirstSearch(),
            'AStar': AStarSearch(),
            'Dijkstra': DijkstraSearch()
        }
        self.current_algorithm = None
        self.current_problem = None
        self.visualization_data = []
    
    def create_maze_problem(self, width: int = 10, height: int = 10, 
                           obstacle_ratio: float = 0.3) -> 'MazeProblem':
        """åˆ›å»ºè¿·å®«é—®é¢˜"""
        maze = np.zeros((height, width))
        
        # éšæœºç”Ÿæˆéšœç¢ç‰©
        for i in range(height):
            for j in range(width):
                if random.random() < obstacle_ratio:
                    maze[i][j] = 1
        
        # ç¡®ä¿èµ·ç‚¹å’Œç»ˆç‚¹å¯é€šè¡Œ
        maze[0][0] = 0
        maze[height-1][width-1] = 0
        
        return MazeProblem(maze, (0, 0), (height-1, width-1))
    
    def run_algorithm(self, algorithm_name: str, problem: 'MazeProblem', 
                     parameters: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œç®—æ³•"""
        if algorithm_name not in self.algorithms:
            raise ValueError(f"æœªçŸ¥ç®—æ³•: {algorithm_name}")
        
        algorithm = self.algorithms[algorithm_name]
        
        # è®¾ç½®å‚æ•°
        for key, value in parameters.items():
            if key in algorithm.get_parameters():
                algorithm.parameters[key] = value
        
        # è¿è¡Œç®—æ³•
        start_time = time.time()
        result = algorithm.run(problem)
        end_time = time.time()
        
        # ç»Ÿè®¡ç»“æœ
        stats = {
            'algorithm': algorithm_name,
            'path_length': len(result['path']) if result['path'] else 0,
            'nodes_explored': result['nodes_explored'],
            'execution_time': end_time - start_time,
            'memory_usage': result['memory_usage'],
            'success': result['path'] is not None
        }
        
        return {
            'path': result['path'],
            'stats': stats,
            'exploration_order': result['exploration_order']
        }
    
    def compare_algorithms(self, problem: 'MazeProblem', 
                          algorithms: List[str]) -> pd.DataFrame:
        """æ¯”è¾ƒå¤šä¸ªç®—æ³•"""
        results = []
        
        for alg_name in algorithms:
            # ä½¿ç”¨é»˜è®¤å‚æ•°è¿è¡Œç®—æ³•
            default_params = self.algorithms[alg_name].get_parameters()
            result = self.run_algorithm(alg_name, problem, default_params)
            results.append(result['stats'])
        
        return pd.DataFrame(results)
    
    def create_animated_visualization(self, problem: 'MazeProblem', 
                                    exploration_order: List[Tuple[int, int]],
                                    path: List[Tuple[int, int]]) -> FuncAnimation:
        """åˆ›å»ºåŠ¨ç”»å¯è§†åŒ–"""
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # åˆå§‹åŒ–æ˜¾ç¤º
        maze_display = problem.maze.copy()
        im = ax.imshow(maze_display, cmap='binary', alpha=0.8)
        
        # æ ‡è®°èµ·ç‚¹å’Œç»ˆç‚¹
        ax.plot(problem.start[1], problem.start[0], 'go', markersize=15, label='èµ·ç‚¹')
        ax.plot(problem.goal[1], problem.goal[0], 'ro', markersize=15, label='ç»ˆç‚¹')
        
        explored_points = ax.scatter([], [], c='yellow', s=50, alpha=0.6, label='å·²æ¢ç´¢')
        path_line, = ax.plot([], [], 'b-', linewidth=3, alpha=0.8, label='æœ€ä¼˜è·¯å¾„')
        
        ax.set_title('æœç´¢ç®—æ³•åŠ¨ç”»æ¼”ç¤º')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        def animate(frame):
            if frame < len(exploration_order):
                # æ˜¾ç¤ºæ¢ç´¢è¿‡ç¨‹
                explored_x = [pos[1] for pos in exploration_order[:frame+1]]
                explored_y = [pos[0] for pos in exploration_order[:frame+1]]
                explored_points.set_offsets(list(zip(explored_x, explored_y)))
            
            if frame >= len(exploration_order) and path:
                # æ˜¾ç¤ºæœ€ä¼˜è·¯å¾„
                path_x = [pos[1] for pos in path]
                path_y = [pos[0] for pos in path]
                path_line.set_data(path_x, path_y)
            
            return [explored_points, path_line]
        
        animation = FuncAnimation(fig, animate, frames=len(exploration_order)+10,
                                interval=100, blit=True, repeat=True)
        
        return animation

# å…·ä½“ç®—æ³•å®ç°
class BreadthFirstSearch(Algorithm):
    """å¹¿åº¦ä¼˜å…ˆæœç´¢"""
    
    def __init__(self):
        super().__init__("BFS")
    
    def get_parameters(self) -> Dict[str, Any]:
        return {
            'max_depth': 100,
            'early_stop': True
        }
    
    def run(self, problem: 'MazeProblem', **kwargs) -> Dict[str, Any]:
        """è¿è¡ŒBFSç®—æ³•"""
        from collections import deque
        
        queue = deque([(problem.start, [problem.start])])
        visited = set([problem.start])
        exploration_order = []
        nodes_explored = 0
        
        while queue:
            current, path = queue.popleft()
            exploration_order.append(current)
            nodes_explored += 1
            
            if current == problem.goal:
                return {
                    'path': path,
                    'nodes_explored': nodes_explored,
                    'exploration_order': exploration_order,
                    'memory_usage': len(queue)
                }
            
            # æ¢ç´¢é‚»å±…
            for neighbor in problem.get_neighbors(current):
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append((neighbor, path + [neighbor]))
        
        return {
            'path': None,
            'nodes_explored': nodes_explored,
            'exploration_order': exploration_order,
            'memory_usage': 0
        }
    
    def visualize(self, data: Any, results: Any) -> None:
        """å¯è§†åŒ–BFSç»“æœ"""
        pass

class DepthFirstSearch(Algorithm):
    """æ·±åº¦ä¼˜å…ˆæœç´¢"""
    
    def __init__(self):
        super().__init__("DFS")
    
    def get_parameters(self) -> Dict[str, Any]:
        return {
            'max_depth': 100,
            'randomize': False
        }
    
    def run(self, problem: 'MazeProblem', **kwargs) -> Dict[str, Any]:
        """è¿è¡ŒDFSç®—æ³•"""
        stack = [(problem.start, [problem.start])]
        visited = set()
        exploration_order = []
        nodes_explored = 0
        
        while stack:
            current, path = stack.pop()
            
            if current in visited:
                continue
            
            visited.add(current)
            exploration_order.append(current)
            nodes_explored += 1
            
            if current == problem.goal:
                return {
                    'path': path,
                    'nodes_explored': nodes_explored,
                    'exploration_order': exploration_order,
                    'memory_usage': len(stack)
                }
            
            # æ¢ç´¢é‚»å±…
            neighbors = problem.get_neighbors(current)
            if self.parameters.get('randomize', False):
                random.shuffle(neighbors)
            
            for neighbor in reversed(neighbors):
                if neighbor not in visited:
                    stack.append((neighbor, path + [neighbor]))
        
        return {
            'path': None,
            'nodes_explored': nodes_explored,
            'exploration_order': exploration_order,
            'memory_usage': 0
        }
    
    def visualize(self, data: Any, results: Any) -> None:
        """å¯è§†åŒ–DFSç»“æœ"""
        pass

class AStarSearch(Algorithm):
    """A*æœç´¢"""
    
    def __init__(self):
        super().__init__("A*")
    
    def get_parameters(self) -> Dict[str, Any]:
        return {
            'heuristic': 'manhattan',
            'weight': 1.0
        }
    
    def run(self, problem: 'MazeProblem', **kwargs) -> Dict[str, Any]:
        """è¿è¡ŒA*ç®—æ³•"""
        import heapq
        
        def heuristic(pos: Tuple[int, int]) -> float:
            if self.parameters.get('heuristic') == 'manhattan':
                return abs(pos[0] - problem.goal[0]) + abs(pos[1] - problem.goal[1])
            else:  # euclidean
                return np.sqrt((pos[0] - problem.goal[0])**2 + (pos[1] - problem.goal[1])**2)
        
        open_set = [(heuristic(problem.start), 0, problem.start, [problem.start])]
        closed_set = set()
        exploration_order = []
        nodes_explored = 0
        
        while open_set:
            f_score, g_score, current, path = heapq.heappop(open_set)
            
            if current in closed_set:
                continue
            
            closed_set.add(current)
            exploration_order.append(current)
            nodes_explored += 1
            
            if current == problem.goal:
                return {
                    'path': path,
                    'nodes_explored': nodes_explored,
                    'exploration_order': exploration_order,
                    'memory_usage': len(open_set)
                }
            
            # æ¢ç´¢é‚»å±…
            for neighbor in problem.get_neighbors(current):
                if neighbor not in closed_set:
                    new_g_score = g_score + 1
                    new_f_score = new_g_score + self.parameters.get('weight', 1.0) * heuristic(neighbor)
                    heapq.heappush(open_set, (new_f_score, new_g_score, neighbor, path + [neighbor]))
        
        return {
            'path': None,
            'nodes_explored': nodes_explored,
            'exploration_order': exploration_order,
            'memory_usage': 0
        }
    
    def visualize(self, data: Any, results: Any) -> None:
        """å¯è§†åŒ–A*ç»“æœ"""
        pass

class DijkstraSearch(Algorithm):
    """Dijkstraç®—æ³•"""
    
    def __init__(self):
        super().__init__("Dijkstra")
    
    def get_parameters(self) -> Dict[str, Any]:
        return {
            'early_stop': True
        }
    
    def run(self, problem: 'MazeProblem', **kwargs) -> Dict[str, Any]:
        """è¿è¡ŒDijkstraç®—æ³•"""
        import heapq
        
        distances = {problem.start: 0}
        previous = {}
        open_set = [(0, problem.start)]
        closed_set = set()
        exploration_order = []
        nodes_explored = 0
        
        while open_set:
            current_dist, current = heapq.heappop(open_set)
            
            if current in closed_set:
                continue
            
            closed_set.add(current)
            exploration_order.append(current)
            nodes_explored += 1
            
            if current == problem.goal:
                # é‡æ„è·¯å¾„
                path = []
                while current in previous:
                    path.append(current)
                    current = previous[current]
                path.append(problem.start)
                path.reverse()
                
                return {
                    'path': path,
                    'nodes_explored': nodes_explored,
                    'exploration_order': exploration_order,
                    'memory_usage': len(open_set)
                }
            
            # æ¢ç´¢é‚»å±…
            for neighbor in problem.get_neighbors(current):
                if neighbor not in closed_set:
                    new_dist = current_dist + 1
                    
                    if neighbor not in distances or new_dist < distances[neighbor]:
                        distances[neighbor] = new_dist
                        previous[neighbor] = current
                        heapq.heappush(open_set, (new_dist, neighbor))
        
        return {
            'path': None,
            'nodes_explored': nodes_explored,
            'exploration_order': exploration_order,
            'memory_usage': 0
        }
    
    def visualize(self, data: Any, results: Any) -> None:
        """å¯è§†åŒ–Dijkstraç»“æœ"""
        pass

# é—®é¢˜å®šä¹‰
@dataclass
class MazeProblem:
    """è¿·å®«é—®é¢˜"""
    maze: np.ndarray
    start: Tuple[int, int]
    goal: Tuple[int, int]
    
    def get_neighbors(self, pos: Tuple[int, int]) -> List[Tuple[int, int]]:
        """è·å–é‚»å±…èŠ‚ç‚¹"""
        neighbors = []
        directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]  # å³ã€ä¸‹ã€å·¦ã€ä¸Š
        
        for dx, dy in directions:
            new_x, new_y = pos[0] + dx, pos[1] + dy
            
            if (0 <= new_x < self.maze.shape[0] and 
                0 <= new_y < self.maze.shape[1] and
                self.maze[new_x][new_y] == 0):
                neighbors.append((new_x, new_y))
        
        return neighbors

# æœºå™¨å­¦ä¹ ç®—æ³•æ¸¸ä¹åœº
class MLAlgorithmPlayground:
    """æœºå™¨å­¦ä¹ ç®—æ³•æ¸¸ä¹åœº"""
    
    def __init__(self):
        self.algorithms = {
            'DecisionTree': DecisionTreePlayground(),
            'KMeans': KMeansPlayground(),
            'NeuralNetwork': NeuralNetworkPlayground()
        }
    
    def generate_classification_data(self, n_samples: int = 300, 
                                   n_features: int = 2, 
                                   n_classes: int = 3,
                                   noise: float = 0.1) -> Tuple[np.ndarray, np.ndarray]:
        """ç”Ÿæˆåˆ†ç±»æ•°æ®"""
        np.random.seed(42)
        
        # ç”Ÿæˆç±»ä¸­å¿ƒ
        centers = np.random.uniform(-5, 5, (n_classes, n_features))
        
        X = []
        y = []
        
        samples_per_class = n_samples // n_classes
        
        for i in range(n_classes):
            # ç”Ÿæˆæ¯ä¸ªç±»çš„æ ·æœ¬
            class_samples = np.random.multivariate_normal(
                centers[i], 
                np.eye(n_features) * noise, 
                samples_per_class
            )
            X.extend(class_samples)
            y.extend([i] * samples_per_class)
        
        return np.array(X), np.array(y)
    
    def generate_regression_data(self, n_samples: int = 100, 
                               n_features: int = 1,
                               noise: float = 0.1) -> Tuple[np.ndarray, np.ndarray]:
        """ç”Ÿæˆå›å½’æ•°æ®"""
        np.random.seed(42)
        
        X = np.random.uniform(-5, 5, (n_samples, n_features))
        
        if n_features == 1:
            y = 2 * X.ravel() + 1 + np.random.normal(0, noise, n_samples)
        else:
            # å¤šç‰¹å¾çº¿æ€§å…³ç³»
            coeffs = np.random.uniform(-2, 2, n_features)
            y = X @ coeffs + np.random.normal(0, noise, n_samples)
        
        return X, y

class DecisionTreePlayground:
    """å†³ç­–æ ‘æ¸¸ä¹åœº"""
    
    def __init__(self):
        self.tree = None
        self.training_history = []
    
    def train(self, X: np.ndarray, y: np.ndarray, 
              max_depth: int = 5, 
              min_samples_split: int = 2,
              criterion: str = 'gini') -> Dict[str, Any]:
        """è®­ç»ƒå†³ç­–æ ‘"""
        # ç®€åŒ–çš„å†³ç­–æ ‘å®ç°
        from collections import Counter
        
        def entropy(labels):
            counts = Counter(labels)
            total = len(labels)
            return -sum((count/total) * np.log2(count/total) for count in counts.values() if count > 0)
        
        def gini(labels):
            counts = Counter(labels)
            total = len(labels)
            return 1 - sum((count/total)**2 for count in counts.values())
        
        def build_tree(X, y, depth=0):
            if depth >= max_depth or len(set(y)) == 1 or len(y) < min_samples_split:
                return {'prediction': Counter(y).most_common(1)[0][0], 'samples': len(y)}
            
            best_feature, best_threshold = None, None
            best_score = float('inf')
            
            n_features = X.shape[1]
            
            for feature in range(n_features):
                thresholds = np.unique(X[:, feature])
                
                for threshold in thresholds:
                    left_mask = X[:, feature] <= threshold
                    right_mask = ~left_mask
                    
                    if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:
                        continue
                    
                    left_y, right_y = y[left_mask], y[right_mask]
                    
                    if criterion == 'entropy':
                        score = (len(left_y) * entropy(left_y) + 
                                len(right_y) * entropy(right_y)) / len(y)
                    else:  # gini
                        score = (len(left_y) * gini(left_y) + 
                                len(right_y) * gini(right_y)) / len(y)
                    
                    if score < best_score:
                        best_score = score
                        best_feature = feature
                        best_threshold = threshold
            
            if best_feature is None:
                return {'prediction': Counter(y).most_common(1)[0][0], 'samples': len(y)}
            
            left_mask = X[:, best_feature] <= best_threshold
            right_mask = ~left_mask
            
            return {
                'feature': best_feature,
                'threshold': best_threshold,
                'left': build_tree(X[left_mask], y[left_mask], depth + 1),
                'right': build_tree(X[right_mask], y[right_mask], depth + 1),
                'samples': len(y)
            }
        
        self.tree = build_tree(X, y)
        
        # è®¡ç®—å‡†ç¡®ç‡
        predictions = [self.predict_single(x) for x in X]
        accuracy = np.mean(predictions == y)
        
        return {
            'accuracy': accuracy,
            'tree_depth': self.get_tree_depth(self.tree),
            'n_nodes': self.count_nodes(self.tree)
        }
    
    def predict_single(self, x: np.ndarray) -> int:
        """å•ä¸ªæ ·æœ¬é¢„æµ‹"""
        if self.tree is None:
            return 0
        
        node = self.tree
        while 'feature' in node:
            if x[node['feature']] <= node['threshold']:
                node = node['left']
            else:
                node = node['right']
        
        return node['prediction']
    
    def get_tree_depth(self, node: Dict) -> int:
        """è·å–æ ‘çš„æ·±åº¦"""
        if 'feature' not in node:
            return 1
        
        left_depth = self.get_tree_depth(node['left'])
        right_depth = self.get_tree_depth(node['right'])
        
        return 1 + max(left_depth, right_depth)
    
    def count_nodes(self, node: Dict) -> int:
        """è®¡ç®—èŠ‚ç‚¹æ•°é‡"""
        if 'feature' not in node:
            return 1
        
        return 1 + self.count_nodes(node['left']) + self.count_nodes(node['right'])

class KMeansPlayground:
    """K-meansæ¸¸ä¹åœº"""
    
    def __init__(self):
        self.centroids = None
        self.labels = None
        self.history = []
    
    def fit(self, X: np.ndarray, k: int = 3, 
            max_iters: int = 100, 
            init_method: str = 'random') -> Dict[str, Any]:
        """è®­ç»ƒK-means"""
        n_samples, n_features = X.shape
        
        # åˆå§‹åŒ–è´¨å¿ƒ
        if init_method == 'random':
            self.centroids = X[np.random.choice(n_samples, k, replace=False)]
        elif init_method == 'kmeans++':
            self.centroids = self._kmeans_plus_plus_init(X, k)
        
        self.history = [self.centroids.copy()]
        
        for iteration in range(max_iters):
            # åˆ†é…æ ·æœ¬åˆ°æœ€è¿‘çš„è´¨å¿ƒ
            distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))
            self.labels = np.argmin(distances, axis=0)
            
            # æ›´æ–°è´¨å¿ƒ
            new_centroids = np.array([X[self.labels == i].mean(axis=0) for i in range(k)])
            
            # æ£€æŸ¥æ”¶æ•›
            if np.allclose(self.centroids, new_centroids):
                break
            
            self.centroids = new_centroids
            self.history.append(self.centroids.copy())
        
        # è®¡ç®—SSE
        sse = sum(np.sum((X[self.labels == i] - self.centroids[i])**2) 
                 for i in range(k))
        
        return {
            'sse': sse,
            'iterations': len(self.history),
            'centroids': self.centroids,
            'labels': self.labels
        }
    
    def _kmeans_plus_plus_init(self, X: np.ndarray, k: int) -> np.ndarray:
        """K-means++åˆå§‹åŒ–"""
        centroids = [X[np.random.randint(X.shape[0])]]
        
        for _ in range(k - 1):
            distances = np.array([min([np.sum((x - c)**2) for c in centroids]) for x in X])
            probabilities = distances / distances.sum()
            cumulative_probs = probabilities.cumsum()
            r = np.random.rand()
            
            for i, prob in enumerate(cumulative_probs):
                if r < prob:
                    centroids.append(X[i])
                    break
        
        return np.array(centroids)

class NeuralNetworkPlayground:
    """ç¥ç»ç½‘ç»œæ¸¸ä¹åœº"""
    
    def __init__(self):
        self.weights = []
        self.biases = []
        self.training_history = []
    
    def init_network(self, layer_sizes: List[int]):
        """åˆå§‹åŒ–ç½‘ç»œ"""
        self.weights = []
        self.biases = []
        
        for i in range(len(layer_sizes) - 1):
            w = np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * 0.1
            b = np.zeros((1, layer_sizes[i + 1]))
            self.weights.append(w)
            self.biases.append(b)
    
    def sigmoid(self, x):
        """Sigmoidæ¿€æ´»å‡½æ•°"""
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
    
    def forward(self, X: np.ndarray) -> np.ndarray:
        """å‰å‘ä¼ æ’­"""
        a = X
        for w, b in zip(self.weights, self.biases):
            z = np.dot(a, w) + b
            a = self.sigmoid(z)
        return a
    
    def train(self, X: np.ndarray, y: np.ndarray, 
              hidden_layers: List[int] = [10],
              learning_rate: float = 0.1,
              epochs: int = 100) -> Dict[str, Any]:
        """è®­ç»ƒç¥ç»ç½‘ç»œ"""
        # æ„å»ºç½‘ç»œç»“æ„
        layer_sizes = [X.shape[1]] + hidden_layers + [len(np.unique(y))]
        self.init_network(layer_sizes)
        
        # è½¬æ¢æ ‡ç­¾ä¸ºone-hotç¼–ç 
        n_classes = len(np.unique(y))
        y_one_hot = np.eye(n_classes)[y]
        
        self.training_history = []
        
        for epoch in range(epochs):
            # å‰å‘ä¼ æ’­
            output = self.forward(X)
            
            # è®¡ç®—æŸå¤±
            loss = np.mean((output - y_one_hot)**2)
            
            # è®¡ç®—å‡†ç¡®ç‡
            predictions = np.argmax(output, axis=1)
            accuracy = np.mean(predictions == y)
            
            self.training_history.append({
                'epoch': epoch,
                'loss': loss,
                'accuracy': accuracy
            })
            
            # ç®€åŒ–çš„åå‘ä¼ æ’­ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰
            # å®é™…åº”ç”¨ä¸­éœ€è¦å®Œæ•´çš„æ¢¯åº¦è®¡ç®—
            
        return {
            'final_loss': loss,
            'final_accuracy': accuracy,
            'training_history': self.training_history
        }

# æ¼”ç¤ºå‡½æ•°
def demo_search_playground():
    """æ¼”ç¤ºæœç´¢ç®—æ³•æ¸¸ä¹åœº"""
    print("ğŸ” æœç´¢ç®—æ³•æ¸¸ä¹åœºæ¼”ç¤º")
    print("="*50)
    
    # åˆ›å»ºæ¸¸ä¹åœºå®ä¾‹
    playground = SearchAlgorithmPlayground()
    
    # åˆ›å»ºè¿·å®«é—®é¢˜
    problem = playground.create_maze_problem(width=8, height=8, obstacle_ratio=0.2)
    
    print(f"è¿·å®«å¤§å°: {problem.maze.shape}")
    print(f"èµ·ç‚¹: {problem.start}")
    print(f"ç»ˆç‚¹: {problem.goal}")
    
    # æµ‹è¯•ä¸åŒç®—æ³•
    algorithms = ['BFS', 'DFS', 'AStar', 'Dijkstra']
    
    for alg_name in algorithms:
        print(f"\næµ‹è¯• {alg_name} ç®—æ³•:")
        
        # è·å–é»˜è®¤å‚æ•°
        default_params = playground.algorithms[alg_name].get_parameters()
        
        # è¿è¡Œç®—æ³•
        result = playground.run_algorithm(alg_name, problem, default_params)
        
        print(f"  è·¯å¾„é•¿åº¦: {result['stats']['path_length']}")
        print(f"  æ¢ç´¢èŠ‚ç‚¹æ•°: {result['stats']['nodes_explored']}")
        print(f"  æ‰§è¡Œæ—¶é—´: {result['stats']['execution_time']:.4f}ç§’")
        print(f"  æˆåŠŸ: {result['stats']['success']}")
    
    # ç®—æ³•æ¯”è¾ƒ
    print("\nğŸ“Š ç®—æ³•æ¯”è¾ƒ:")
    comparison_df = playground.compare_algorithms(problem, algorithms)
    print(comparison_df.to_string(index=False))

def demo_ml_playground():
    """æ¼”ç¤ºæœºå™¨å­¦ä¹ æ¸¸ä¹åœº"""
    print("\nğŸ§  æœºå™¨å­¦ä¹ ç®—æ³•æ¸¸ä¹åœºæ¼”ç¤º")
    print("="*50)
    
    # åˆ›å»ºæ¸¸ä¹åœºå®ä¾‹
    playground = MLAlgorithmPlayground()
    
    # ç”Ÿæˆæ•°æ®
    X, y = playground.generate_classification_data(n_samples=200, n_classes=3)
    
    print(f"æ•°æ®é›†å¤§å°: {X.shape}")
    print(f"ç±»åˆ«æ•°: {len(np.unique(y))}")
    
    # å†³ç­–æ ‘æ¼”ç¤º
    print("\nğŸŒ³ å†³ç­–æ ‘æ¼”ç¤º:")
    dt = DecisionTreePlayground()
    
    # æµ‹è¯•ä¸åŒå‚æ•°
    depths = [3, 5, 7]
    
    for depth in depths:
        result = dt.train(X, y, max_depth=depth)
        print(f"  æ·±åº¦={depth}: å‡†ç¡®ç‡={result['accuracy']:.3f}, èŠ‚ç‚¹æ•°={result['n_nodes']}")
    
    # K-meansæ¼”ç¤º
    print("\nğŸ¯ K-meansæ¼”ç¤º:")
    kmeans = KMeansPlayground()
    
    # æµ‹è¯•ä¸åŒKå€¼
    k_values = [2, 3, 4, 5]
    
    for k in k_values:
        result = kmeans.fit(X, k=k)
        print(f"  K={k}: SSE={result['sse']:.2f}, è¿­ä»£æ¬¡æ•°={result['iterations']}")

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    demo_search_playground()
    demo_ml_playground() 